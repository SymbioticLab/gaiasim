package gaiasim.scheduler;

// The scheduler for Siphon
// Paper ref: https://www.usenix.org/system/files/conference/atc18/atc18-liu.pdf

// How to implement Siphon scheduler?
// Use Oracle FCT to sort Coflows
// Use LFGF to schedule flows of a Coflow
// After scheduling, run the bottleneck shifting algorithm for multipath


import com.opencsv.CSVReader;
import gaiasim.network.*;

import java.io.IOException;
import java.io.Reader;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Collectors;

public class SiphonScheduler extends BaselineScheduler {

    int monteCarloDepth = 10; // default depth = 10
    int multipathIterations = 10; // default, iterate the process of shifting traffic 10 times
    Map<String, Double> oracleCCT = new HashMap<>();

    public SiphonScheduler(NetGraph net_graph, String oracleCCT_filename) {
        super(net_graph);
        readOracleCCT(oracleCCT_filename);
    }

    // method called in constructor should be final.
    private final void readOracleCCT(String oracleFCT_filename) {

        // read in a list of flow completion time, as the oracleCCT
        // The oracle CCT should be a csv file generated by the per-flow solution (ideally with one-by-one option)

        try (
                Reader reader = Files.newBufferedReader(Paths.get(oracleFCT_filename));
                CSVReader csvReader = new CSVReader(reader, ',', '"', 1)
        ) {
            // Reading Records One by One in a String array
            String[] nextRecord;
            while ((nextRecord = csvReader.readNext()) != null) {
//                System.out.println("CF ID : " + nextRecord[0]);
//                System.out.println("Start : " + nextRecord[1]);
//                System.out.println("End : " + nextRecord[2]);
//                System.out.println("CCT : " + nextRecord[3]);
//                System.out.println("==========================");
                oracleCCT.put(nextRecord[0], Double.parseDouble(nextRecord[3]));
            }
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    @Override
    public HashMap<String, Flow> schedule_flows(HashMap<String, Coflow> coflows, long timestamp) throws Exception {
        flows_.clear();

        // Hashmap or list?
//        HashMap<String, Coflow> coflows_to_schedule = (HashMap<String, Coflow>) coflows.clone();
        Collection<Coflow> coflows_to_schedule = coflows.values();

        while (!coflows_to_schedule.isEmpty()) {

            // Use Oracle FCT to sort Coflows to find the next coflow to schedule
            Coflow cf_to_schedule = findNextCoflow_fromCCT(coflows_to_schedule);

            // We consider one coflow at a time
            coflows_to_schedule.clear();

            // TODO verify that this coflow is fully schedulable?

            // TODO LFGF to schedule flows of a Coflow
            // 1. group flows by their reduce task (dst loc), and find the ones with the biggest size

            Map<String, Double> FG_Size_Map = cf_to_schedule.flows_.values().stream().collect(Collectors.groupingBy(
                    Flow::getDst_loc_, Collectors.summingDouble(Flow::remaining_volume)));

            LinkedList<Map.Entry<String, Double>> FG_Size_list = new LinkedList<>(FG_Size_Map.entrySet());
            FG_Size_list.sort(Map.Entry.comparingByValue());
            // TODO break point here and verify the order

            // 2. TODO find the shortest path for each flow and allocate BW
// Ignore coflow that cannot be scheduled in its entirety

            for (Map.Entry<String, Double> fge : FG_Size_list) {
                String dst_loc = fge.getKey();

                // Find all flows that have this dst_loc, and schedule them

                for (Map.Entry<String, Flow> flowEntry : cf_to_schedule.flows_.entrySet()) {
                    Flow f = flowEntry.getValue();
                    // Ensure this flow is not done and also is within the prioritized group
                    if (f.done_ || f.dst_loc_.equals(dst_loc)) {
                        continue;
                    }

                    Pathway p = new Pathway(net_graph_.apsp_[Integer.parseInt(f.src_loc_)][Integer.parseInt(f.dst_loc_)]);
                    f.paths_.clear();
                    f.paths_.add(p);

                    for (int i = 0; i < p.node_list_.size() - 1; i++) {
                        int src = Integer.parseInt(p.node_list_.get(i));
                        int dst = Integer.parseInt(p.node_list_.get(i + 1));
                        links_[src][dst].subscribers_.addAll(f.paths_);
                    }

                    if (f.start_timestamp_ == -1) {
                        f.start_timestamp_ = timestamp;
                    }

                    flows_.put(f.id_, f);
                }

            }


            // TODO After scheduling, run the bottleneck shifting algorithm for multipath

            // TODO remove the schedule coflow from the collection and run again

        }

        update_flows(flows_);       // FIXME: verify

        return flows_;
    }

    // Find the next coflow to schedule (the one with min CCT)

    private Coflow findNextCoflow_fromCCT(Collection<Coflow> coflows_to_schedule) {

        //        Don't use Monte Carlo here, because the duration is deterministic
//        int depth = Math.min(monteCarloDepth, coflows_to_schedule.size());

        Coflow ret = null;
        double minCCT = Double.MAX_VALUE;
        // Iterate through all coflows and find the one with min CCT
        for (Coflow cf : coflows_to_schedule) {

            // Get Max FCT for this coflow
            Double cct = oracleCCT.get(cf.id_);
            if (cct != null && minCCT > cct) {
                minCCT = cct;
                ret = cf;
            }
        }

        return ret;
    }

    // Updates the rates of flows
    public void update_flows(HashMap<String, Flow> flows) {
        for (String k : flows.keySet()) {
            Flow f = flows.get(k);

            double min_bw = Double.MAX_VALUE;

            ArrayList<String> nodes = f.paths_.get(0).node_list_;
            for (int i = 0; i < nodes.size() - 1; i++) {
                int src = Integer.parseInt(nodes.get(i));
                int dst = Integer.parseInt(nodes.get(i + 1));
                double link_bw = links_[src][dst].bw_per_flow();

                if (link_bw < min_bw) {
                    min_bw = link_bw;
                }
            }

            f.rate_ = min_bw;
            System.out.println("Flow " + f.id_ + " has rate " + f.rate_ + " and remaining volume " + (f.volume_ - f.transmitted_) + " on path " + f.paths_.get(0));
        }
    }

   /* private Coflow findNextCoflow_fromFCT(Collection<Coflow> coflows_to_schedule) {

//        Don't use Monte Carlo here, because the duration is deterministic
//        int depth = Math.min(monteCarloDepth, coflows_to_schedule.size());

        Coflow ret = null;
        double minCCT = Double.MAX_VALUE;
        // Iterate through all coflows and find the one with min CCT
        for (Coflow cf : coflows_to_schedule) {

            // Get Max FCT for this coflow
            double maxFCT = 0;
            for (Flow f : cf.flows_.values()) {
                Double fct = oracleFCT.get(f.id_);
                if (fct != null && fct > maxFCT) {
                    maxFCT = fct;
                }
            }

            if (maxFCT != 0 && maxFCT < minCCT) {
                minCCT = maxFCT;
                ret = cf;
            }
        }

        return ret;
    }*/
}
